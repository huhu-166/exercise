{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4b0b05",
   "metadata": {},
   "source": [
    "Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e9d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import torchvision  \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b48ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d1365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9046fed",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da08664",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(0.5),\n",
    "    #transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# 下载FashionMNIST数据集  \n",
    "fmnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "fmnist_text = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform) \n",
    "# 定义数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    fmnist_train, batch_size=batch_size, shuffle=True)\n",
    "text_loader = torch.utils.data.DataLoader(\n",
    "    fmnist_text, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b07de",
   "metadata": {},
   "source": [
    "Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd327f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netcnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netcnn, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class Netmlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netmlp,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d898a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "netcnn=Netcnn().to(device)\n",
    "netmlp=Netmlp().to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(netcnn.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(netmlp.parameters(), lr=1e-4,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902dc46",
   "metadata": {},
   "source": [
    "Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36573343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,net,optimizer): \n",
    "    net.train()\n",
    "    train_loss=0\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += l.item()*X.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "        \n",
    "def validate(epoch,net,optimizer):\n",
    "    net.eval()\n",
    "    val_loss=0\n",
    "    gt_labels=[]\n",
    "    pred_labels=[]\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(text_loader):\n",
    "            X, y = X.to(device), y.to(device)   \n",
    "            y_hat=net(X)\n",
    "            preds=torch.argmax(y_hat,1)\n",
    "            gt_labels.append(y.cpu().data.numpy())\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            l = loss(y_hat, y)\n",
    "            val_loss+=l.item()*X.size(0)\n",
    "    val_loss=val_loss/len(text_loader.dataset)\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718230bd",
   "metadata": {},
   "source": [
    "Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3b1463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.005033\n",
      "Epoch: 1 \tValidation Loss: 0.624601, Accuracy: 0.768400\n",
      "Epoch: 2 \tTraining Loss: 0.593426\n",
      "Epoch: 2 \tValidation Loss: 0.529950, Accuracy: 0.809900\n",
      "Epoch: 3 \tTraining Loss: 0.522256\n",
      "Epoch: 3 \tValidation Loss: 0.480018, Accuracy: 0.827900\n",
      "Epoch: 4 \tTraining Loss: 0.477795\n",
      "Epoch: 4 \tValidation Loss: 0.443286, Accuracy: 0.845800\n",
      "Epoch: 5 \tTraining Loss: 0.445716\n",
      "Epoch: 5 \tValidation Loss: 0.418126, Accuracy: 0.851900\n",
      "Epoch: 6 \tTraining Loss: 0.423557\n",
      "Epoch: 6 \tValidation Loss: 0.395312, Accuracy: 0.861200\n",
      "Epoch: 7 \tTraining Loss: 0.404833\n",
      "Epoch: 7 \tValidation Loss: 0.383179, Accuracy: 0.864200\n",
      "Epoch: 8 \tTraining Loss: 0.391741\n",
      "Epoch: 8 \tValidation Loss: 0.369297, Accuracy: 0.869400\n",
      "Epoch: 9 \tTraining Loss: 0.376240\n",
      "Epoch: 9 \tValidation Loss: 0.361122, Accuracy: 0.871100\n",
      "Epoch: 10 \tTraining Loss: 0.365791\n",
      "Epoch: 10 \tValidation Loss: 0.349366, Accuracy: 0.875600\n",
      "Epoch: 11 \tTraining Loss: 0.354791\n",
      "Epoch: 11 \tValidation Loss: 0.340688, Accuracy: 0.879100\n",
      "Epoch: 12 \tTraining Loss: 0.346946\n",
      "Epoch: 12 \tValidation Loss: 0.335783, Accuracy: 0.879000\n",
      "Epoch: 13 \tTraining Loss: 0.337673\n",
      "Epoch: 13 \tValidation Loss: 0.328571, Accuracy: 0.882400\n",
      "Epoch: 14 \tTraining Loss: 0.332320\n",
      "Epoch: 14 \tValidation Loss: 0.321332, Accuracy: 0.885000\n",
      "Epoch: 15 \tTraining Loss: 0.325902\n",
      "Epoch: 15 \tValidation Loss: 0.315447, Accuracy: 0.885400\n",
      "Epoch: 16 \tTraining Loss: 0.318457\n",
      "Epoch: 16 \tValidation Loss: 0.308676, Accuracy: 0.888100\n",
      "Epoch: 17 \tTraining Loss: 0.314098\n",
      "Epoch: 17 \tValidation Loss: 0.305233, Accuracy: 0.891700\n",
      "Epoch: 18 \tTraining Loss: 0.308358\n",
      "Epoch: 18 \tValidation Loss: 0.299292, Accuracy: 0.893500\n",
      "Epoch: 19 \tTraining Loss: 0.304218\n",
      "Epoch: 19 \tValidation Loss: 0.295316, Accuracy: 0.893400\n",
      "Epoch: 20 \tTraining Loss: 0.299854\n",
      "Epoch: 20 \tValidation Loss: 0.293889, Accuracy: 0.895300\n",
      "Epoch: 21 \tTraining Loss: 0.293653\n",
      "Epoch: 21 \tValidation Loss: 0.290569, Accuracy: 0.896800\n",
      "Epoch: 22 \tTraining Loss: 0.290077\n",
      "Epoch: 22 \tValidation Loss: 0.284914, Accuracy: 0.898200\n",
      "Epoch: 23 \tTraining Loss: 0.286048\n",
      "Epoch: 23 \tValidation Loss: 0.286481, Accuracy: 0.897700\n",
      "Epoch: 24 \tTraining Loss: 0.280709\n",
      "Epoch: 24 \tValidation Loss: 0.282005, Accuracy: 0.899100\n",
      "Epoch: 25 \tTraining Loss: 0.276246\n",
      "Epoch: 25 \tValidation Loss: 0.283880, Accuracy: 0.898200\n",
      "Epoch: 26 \tTraining Loss: 0.273915\n",
      "Epoch: 26 \tValidation Loss: 0.276220, Accuracy: 0.898900\n",
      "Epoch: 27 \tTraining Loss: 0.269796\n",
      "Epoch: 27 \tValidation Loss: 0.281095, Accuracy: 0.896800\n",
      "Epoch: 28 \tTraining Loss: 0.268398\n",
      "Epoch: 28 \tValidation Loss: 0.268940, Accuracy: 0.903700\n",
      "Epoch: 29 \tTraining Loss: 0.263888\n",
      "Epoch: 29 \tValidation Loss: 0.269950, Accuracy: 0.905000\n",
      "Epoch: 30 \tTraining Loss: 0.259937\n",
      "Epoch: 30 \tValidation Loss: 0.267599, Accuracy: 0.903800\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch, netcnn, optimizer1)\n",
    "    validate(epoch, netcnn, optimizer1)\n",
    "save_path = \"./FahionCNN.pkl\"\n",
    "torch.save(netcnn, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab160ba3",
   "metadata": {},
   "source": [
    "Train MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d3775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.318977\n",
      "Epoch: 1 \tValidation Loss: 0.687434, Accuracy: 0.750900\n",
      "Epoch: 2 \tTraining Loss: 0.674261\n",
      "Epoch: 2 \tValidation Loss: 0.559956, Accuracy: 0.796000\n",
      "Epoch: 3 \tTraining Loss: 0.566433\n",
      "Epoch: 3 \tValidation Loss: 0.503952, Accuracy: 0.819400\n",
      "Epoch: 4 \tTraining Loss: 0.516129\n",
      "Epoch: 4 \tValidation Loss: 0.476583, Accuracy: 0.825600\n",
      "Epoch: 5 \tTraining Loss: 0.482364\n",
      "Epoch: 5 \tValidation Loss: 0.460137, Accuracy: 0.835100\n",
      "Epoch: 6 \tTraining Loss: 0.457860\n",
      "Epoch: 6 \tValidation Loss: 0.445950, Accuracy: 0.836500\n",
      "Epoch: 7 \tTraining Loss: 0.438615\n",
      "Epoch: 7 \tValidation Loss: 0.428545, Accuracy: 0.844700\n",
      "Epoch: 8 \tTraining Loss: 0.423885\n",
      "Epoch: 8 \tValidation Loss: 0.419911, Accuracy: 0.847600\n",
      "Epoch: 9 \tTraining Loss: 0.413067\n",
      "Epoch: 9 \tValidation Loss: 0.410816, Accuracy: 0.850200\n",
      "Epoch: 10 \tTraining Loss: 0.399553\n",
      "Epoch: 10 \tValidation Loss: 0.403696, Accuracy: 0.852200\n",
      "Epoch: 11 \tTraining Loss: 0.390782\n",
      "Epoch: 11 \tValidation Loss: 0.397937, Accuracy: 0.852900\n",
      "Epoch: 12 \tTraining Loss: 0.380328\n",
      "Epoch: 12 \tValidation Loss: 0.389863, Accuracy: 0.858700\n",
      "Epoch: 13 \tTraining Loss: 0.373360\n",
      "Epoch: 13 \tValidation Loss: 0.385471, Accuracy: 0.860300\n",
      "Epoch: 14 \tTraining Loss: 0.365705\n",
      "Epoch: 14 \tValidation Loss: 0.384393, Accuracy: 0.860300\n",
      "Epoch: 15 \tTraining Loss: 0.358910\n",
      "Epoch: 15 \tValidation Loss: 0.385231, Accuracy: 0.860100\n",
      "Epoch: 16 \tTraining Loss: 0.351546\n",
      "Epoch: 16 \tValidation Loss: 0.373553, Accuracy: 0.865500\n",
      "Epoch: 17 \tTraining Loss: 0.345972\n",
      "Epoch: 17 \tValidation Loss: 0.367993, Accuracy: 0.866000\n",
      "Epoch: 18 \tTraining Loss: 0.339890\n",
      "Epoch: 18 \tValidation Loss: 0.368814, Accuracy: 0.866700\n",
      "Epoch: 19 \tTraining Loss: 0.335265\n",
      "Epoch: 19 \tValidation Loss: 0.363102, Accuracy: 0.869900\n",
      "Epoch: 20 \tTraining Loss: 0.330442\n",
      "Epoch: 20 \tValidation Loss: 0.358113, Accuracy: 0.872300\n",
      "Epoch: 21 \tTraining Loss: 0.325068\n",
      "Epoch: 21 \tValidation Loss: 0.359692, Accuracy: 0.871700\n",
      "Epoch: 22 \tTraining Loss: 0.321563\n",
      "Epoch: 22 \tValidation Loss: 0.358857, Accuracy: 0.871800\n",
      "Epoch: 23 \tTraining Loss: 0.317012\n",
      "Epoch: 23 \tValidation Loss: 0.354887, Accuracy: 0.873600\n",
      "Epoch: 24 \tTraining Loss: 0.311832\n",
      "Epoch: 24 \tValidation Loss: 0.349099, Accuracy: 0.874600\n",
      "Epoch: 25 \tTraining Loss: 0.305079\n",
      "Epoch: 25 \tValidation Loss: 0.347404, Accuracy: 0.876100\n",
      "Epoch: 26 \tTraining Loss: 0.302753\n",
      "Epoch: 26 \tValidation Loss: 0.349298, Accuracy: 0.874400\n",
      "Epoch: 27 \tTraining Loss: 0.300089\n",
      "Epoch: 27 \tValidation Loss: 0.345773, Accuracy: 0.877000\n",
      "Epoch: 28 \tTraining Loss: 0.296948\n",
      "Epoch: 28 \tValidation Loss: 0.349749, Accuracy: 0.873400\n",
      "Epoch: 29 \tTraining Loss: 0.294055\n",
      "Epoch: 29 \tValidation Loss: 0.342903, Accuracy: 0.879500\n",
      "Epoch: 30 \tTraining Loss: 0.290673\n",
      "Epoch: 30 \tValidation Loss: 0.344492, Accuracy: 0.879400\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch,netmlp,optimizer2)\n",
    "    validate(epoch,netmlp,optimizer2)\n",
    "save_path = \"./FahionMLP.pkl\"\n",
    "torch.save(netmlp, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
